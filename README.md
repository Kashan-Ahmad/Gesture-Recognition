# Hand Gesture Classification with CNNs and Transfer Learning

This project was completed as part of the APS360 course at the University of Toronto. The objective was to classify 9 hand gestures from RGB images using both a custom-built Convolutional Neural Network (CNN) and a Transfer Learning approach leveraging AlexNet.

## üìå Overview

The project involved:
- Building a CNN from scratch using PyTorch to classify 224√ó224 RGB images into 9 gesture classes (A‚ÄìI).
- Experimenting with architecture-related hyperparameters like kernel size, stride, and padding.
- Fine-tuning performance through batch size and learning rate adjustments.
- Applying Transfer Learning using AlexNet to extract convolutional features, followed by training a smaller classification network.
- Tracking accuracy and visualizing training curves.

## ‚úÖ Results

- **Custom CNN**:  
  - Validation Accuracy: ~70%  
  - Test Accuracy: ~72%

- **AlexNet Transfer Learning**:  
  - Validation Accuracy: ~94%  
  - Test Accuracy: ~93%

## üß† Skills Demonstrated

- Deep learning model architecture and debugging in PyTorch  
- Hyperparameter tuning and performance optimization  
- Transfer learning with pretrained models  
- Training visualization and accuracy tracking

## ‚ö†Ô∏è Note

This project was completed for academic purposes and is **not intended for reuse or distribution**.


